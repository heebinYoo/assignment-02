{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assign02.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ehAPKBhRIPN2EmWwbPj3aguZ5RpQkM-Y","authorship_tag":"ABX9TyPoqfWOHVXZFP/m3O31oiXL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"88d7f6075b3c4da48942edbe57e1e4ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_700a82d9f9464765aa0b7c4449d847cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e4d1a50cd89743acac517d32aabf0e5a","IPY_MODEL_7b24e894e4d748659b59778154a401e5"]}},"700a82d9f9464765aa0b7c4449d847cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4d1a50cd89743acac517d32aabf0e5a":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5f6001c70fa54f53ab9a6f56390b234d","_dom_classes":[],"description":" 45%","_model_name":"IntProgressModel","bar_style":"","max":2000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":904,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62e2e52b96cf4c21928cd594772ebba9"}},"7b24e894e4d748659b59778154a401e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_738351a871ec4619abe83d83dea2fde4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 904/2000 [00:10&lt;00:12, 85.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c8633665a304306b50d0819fb7a29bf"}},"5f6001c70fa54f53ab9a6f56390b234d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"62e2e52b96cf4c21928cd594772ebba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"738351a871ec4619abe83d83dea2fde4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c8633665a304306b50d0819fb7a29bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"j2NoeBoUHzO0","colab_type":"code","colab":{}},"source":["import numpy as np\n","import random as rd\n","import matplotlib.pylab as plt\n","from matplotlib import cm\n","\n","\n","data    = np.genfromtxt(\"/content/drive/My Drive/Colab Notebooks/assignment-02/data-nonlinear.txt\", delimiter=',')\n","\n","x       = data[:, 0]\n","y       = data[:, 1]\n","label   = data[:, 2]\n","\n","\n","x_label0    = x[label == 0]\n","y_label0    = y[label == 0]\n","\n","x_label1    = x[label == 1]\n","y_label1    = y[label == 1]\n","\n","lb_0 = np.column_stack([x_label0, y_label0, np.zeros(len(x_label0))])\n","lb_1 = np.column_stack([x_label1, y_label1, np.ones(len(x_label1))])\n","\n","\n","train_set = np.vstack([lb_0,lb_1])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4N5g09a68aQo","colab_type":"code","colab":{}},"source":["functions =[lambda x,y: 1, lambda x,y: x, lambda x,y: y, lambda x,y: x*y,    \\\n","                lambda x,y: x**2, lambda x,y: y**2, lambda x,y: y**4, lambda x,y: y**4, lambda x,y: y**2 * x**2,   \\\n","            lambda x,y: x**2 * y **6 ,lambda x,y: x**6 * y**2,lambda x,y: x**6,lambda x,y: y**6,lambda x,y: x**4 * y**4, \\\n","            lambda x,y: x**8,lambda x,y: y**8]\n","\n","\n","def f(data):\n","    result = []\n","    for func in functions:\n","        result.append(list(map(func, data[0,:], data[1,:])))\n","    return np.array(result)\n","\n","def partialDiff(j):\n","    return list(map(functions[j], train_set[:,0], train_set[:,1]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2dLTrGXh8KT","colab_type":"code","colab":{}},"source":["alpha = 3\n","m = len(train_set)\n","\n","def z(th, x):\n","    return np.matmul(th,f(x))\n","def h(th, x):\n","    return 1 / (1 +np.exp(-z(th, x)))\n","def J(th, data): \n","    return (1/(m)) * np.sum(                                                   \\\n","        - data[:,2] * np.log(h(th,np.transpose(data[:,0:2])))                  \\\n","        - (1-data[:,2]) * np.log(1 - h(th,np.transpose(data[:,0:2])))          \\\n","        )\n","def accuracy():\n","    answer = train_set[:,2]\n","    guess = np.around(h(g_th,np.transpose(train_set[:,0:2])))\n","    return np.sum(np.equal(answer, guess)) / m\n","\n","\n","def th_cal(th):\n","    result = []\n","    diff = (h(th, np.transpose(train_set[:,0:2])) - train_set[:,2])\n","    for j in range(len(th)):\n","        result.append( th[j]-(alpha * (1/m) * np.sum(  diff * partialDiff(j) )) )\n","    return np.array(result)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_arw0d8robIc","colab_type":"code","colab":{}},"source":["g_th = np.array([4,1,1,2,1,1,2,1,1,4,1,1,2,1,1,2])\n","J_log_train = [J(g_th, train_set)]\n","th_log = [g_th]\n","accuracy_log = [accuracy()]\n","\n","# import sys\n","e = 5*10 ** (-14)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WL54_SThwyBq","colab_type":"code","outputId":"971a07de-56b8-4d0a-a77c-b228c7b5185c","executionInfo":{"status":"ok","timestamp":1587720417406,"user_tz":-540,"elapsed":71672,"user":{"displayName":"유희빈","photoUrl":"","userId":"10466890457494242203"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["88d7f6075b3c4da48942edbe57e1e4ff","700a82d9f9464765aa0b7c4449d847cc","e4d1a50cd89743acac517d32aabf0e5a","7b24e894e4d748659b59778154a401e5","5f6001c70fa54f53ab9a6f56390b234d","62e2e52b96cf4c21928cd594772ebba9","738351a871ec4619abe83d83dea2fde4","8c8633665a304306b50d0819fb7a29bf"]}},"source":["from tqdm.notebook import tqdm\n","for i in tqdm(range(2000)):\n","    g_th = th_cal(g_th)\n","    J_log_train.append(J(g_th, train_set))\n","    th_log.append(g_th)\n","    accuracy_log.append(accuracy())\n","    if abs(J(g_th, train_set) - J_log_train[-2]) <=e and np.sum (g_th -th_log[-2]) <= 4*e:\n","        break\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88d7f6075b3c4da48942edbe57e1e4ff","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SgTic_esa2ra","colab":{}},"source":["print(J_log_train[-2])\n","accuracy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVe1GoDLwinZ","colab_type":"text"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"sw0qZ58MBWEF","colab_type":"text"},"source":["#로지스틱 회귀 실습\n","\n","##### 1. Plot the training data [2pt]\n","- plot the training data points $(x, y)$ with their labels $l$ in colors (blue for label 0 and red for label 1)\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"lfiV0v8MCUPF","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8, 8))\n","plt.scatter(x_label0, y_label0, c='b')\n","plt.scatter(x_label1, y_label1, c='r')\n","plt.tight_layout()\n","plt.gca().set_aspect('equal', adjustable='box')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Tq9dS3d8bCY","colab_type":"text"},"source":["##### 2. Write down the high dimensional function $g(x, y; \\theta)$ [2pt]\n","- write down the equation for the non-linear function $g(x, y; \\theta)$ used for the classifier in LaTeX format  \n","\n","$$\n","let F = (f_0(x,y), f_1(x,y), f_2(x,y), f_3(x,y),\\dots) \\\\\n","f_0(x,y) = 1 \\\\\n","f_1(x,y) = x \\\\\n","f_2(x,y) = y \\\\\n","f_3(x,y) = xy \\\\\n","f_4(x,y) = x^2 \\\\\n","f_5(x,y) = y^2 \\\\\n","f_6(x,y) = x^4 \\\\\n","f_7(x,y) = y^4 \\\\\n","f_8(x,y) = x^2y^2 \\\\\n","f_9(x,y) = x^2y^6 \\\\\n","f_{10}(x,y) = x^6y^2 \\\\\n","f_{11}(x,y) = x^6 \\\\\n","f_{12}(x,y) = y^6 \\\\\n","f_{13}(x,y) = x^4y^4 \\\\\n","f_{14}(x,y) = x^8 \\\\\n","f_{15}(x,y) = y^8 \\\\\n","g(x, y ; \\theta) = \\theta_{0} f_{0}(x, y) + \\theta_{1} f_{1}(x, y) + \\cdots + \\theta_{k-1} f_{k-1}(x, y) = \\theta \\cdot F\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"Eu-iiL4NlMnY","colab_type":"text"},"source":["\n","##### 3. Plot the training error [3pt]\n","- plot the training error $J(\\theta_0, \\theta_1, \\theta_2)$ at every iteration of gradient descent until convergence (in blue color)\n","\n"]},{"cell_type":"code","metadata":{"id":"bNm0RRR4lTB9","colab_type":"code","colab":{}},"source":["plt.plot(J_log_train,c='blue')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sy8sRGAyBQqq","colab_type":"text"},"source":["##### 4. Plot the training accuracy [3pt]\n","- plot the training accuracy at every iteration of gradient descent until convergence (in red color)\n","\n"]},{"cell_type":"code","metadata":{"id":"6ItHIeoGBRFE","colab_type":"code","colab":{}},"source":["plt.plot(accuracy_log,c='red')\n","plt.show()\n","len(accuracy_log)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NVpSGyMfBRas","colab_type":"text"},"source":["##### 5. Write down the final training accuracy [2pt]\n","- the final training accuracy at convergence\n"]},{"cell_type":"code","metadata":{"id":"tURbhcITbntT","colab_type":"code","colab":{}},"source":["accuracy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MjTaMMNbBTU6","colab_type":"text"},"source":["\n","##### 6. Plot the optimal classifier superimposed on the training data [5pt]\n","- plot the boundary of the optimal classifier at convergence (in green color)\n","- the boundary of the classifier is defined by $\\{ (x, y) \\mid \\sigma(g(x, y ; \\theta)) = 0.5 \\} = \\{ (x, y) \\mid g(x, y ; \\theta) = 0 \\}$\n","- plot the training data points $(x, y)$ with their labels $l$ in colors superimposed on the illustration of the classifier (blue for label 0 and red for label 1)\n","- you can use `contour` function in python3\n"]},{"cell_type":"code","metadata":{"id":"DWjt3JQbBltg","colab_type":"code","colab":{}},"source":["X, Y = np.meshgrid(np.linspace(-0.9, 1.2, 1000), np.linspace(-0.9, 1.2, 1000))\n","\n","\n","Z = np.array([  np.around(   h(g_th, np.array([x,y]) )   ) for x,y in zip(X,Y)  ])\n","\n","plt.figure(figsize=(8, 8))\n","plt.contour(X, Y, Z, cmap='Greens')\n","\n","plt.scatter(x_label0, y_label0, c='b')\n","plt.scatter(x_label1, y_label1, c='r')\n","plt.tight_layout()\n","plt.gca().set_aspect('equal', adjustable='box')\n","\n","\n","plt.show()\n","\n"],"execution_count":0,"outputs":[]}]}